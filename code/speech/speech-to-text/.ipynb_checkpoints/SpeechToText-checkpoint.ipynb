{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer to the Speech to Text 3.0 Swagger documentation: https://develop.cris.ai/swagger/ui/index?urls.primaryName=Speech%20Services%20API%20v3.0#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import time\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech to Text region\n",
    "region = \"westeurope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech to Text - subscription key\n",
    "SUBSCRIPTION_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storage Account connection string and SAS key\n",
    "connect_str = ''\n",
    "SAS = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## storage account - account name and container name. This where we store the audio files\n",
    "#container_name = \"datamultiplevoices\"\n",
    "container_name = \"speechdata\"\n",
    "\n",
    "account_name = \"fimscogstorage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech to Text Endpoint for Transcriptions \n",
    "\n",
    "BaseURL =\"https://\" + region + \".api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/\"\n",
    "EndpointURL = \"https://\" + region + \".api.cognitive.microsoft.com/speechtotext/v3.0/endpoints/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storage path\n",
    "STORAGE_PATH=\"https://\" + account_name + \".blob.core.windows.net/\" + container_name + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare HTTP POST Request Body with associated Speech to Text properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                \"customProperties\": {\n",
    "                    \"diarizationV3Enabled\": true\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech to Text - transcription properties\n",
    "def bulkTranscription(blob_uri, blob_name):\n",
    "    BD = \"\"\"\n",
    "            {\n",
    "                \"contentUrls\": [ \n",
    "                    \"__URL__\"],\n",
    "                \"locale\": \"en-US\",\n",
    "                \"displayName\": \"blob_name\",\n",
    "                \"properties\": {\n",
    "                    \"punctuationMode\": \"Automatic\",\n",
    "                    \"profanityFilterMode\": \"Masked\",\n",
    "                    \"wordLevelTimestampsEnabled\": \"False\",\n",
    "                    \"diarizationEnabled\" : \"False\"\n",
    "                }\n",
    "\n",
    "            }\n",
    "            \"\"\"\n",
    "    BD = BD.replace(\"__URL__\", URL)  \n",
    "    BD = BD.replace(\"blob_name\", blobname)\n",
    "    return BD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize HTTP POST request headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the connection to our Blob storage account and container. Store the list of blobs in blob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blob_list = container_client.list_blobs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iterator object azure.core.paging.ItemPaged at 0x2242be69f40>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every blob (audio file) in our storage account container call the Speech to Text REST API and transcribe the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taudio.wav\n",
      "{\n",
      "  \"self\": \"https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b\",\n",
      "  \"model\": {\n",
      "    \"self\": \"https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/models/base/bb14a731-ed79-407f-b8dc-61f457c79db4\"\n",
      "  },\n",
      "  \"links\": {\n",
      "    \"files\": \"https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b/files\"\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"diarizationEnabled\": false,\n",
      "    \"wordLevelTimestampsEnabled\": false,\n",
      "    \"channels\": [\n",
      "      0,\n",
      "      1\n",
      "    ],\n",
      "    \"punctuationMode\": \"Automatic\",\n",
      "    \"profanityFilterMode\": \"Masked\"\n",
      "  },\n",
      "  \"lastActionDateTime\": \"2022-06-16T06:31:16Z\",\n",
      "  \"status\": \"NotStarted\",\n",
      "  \"createdDateTime\": \"2022-06-16T06:31:16Z\",\n",
      "  \"locale\": \"en-US\",\n",
      "  \"displayName\": \"audio.wav\"\n",
      "}\n",
      "{'self': 'https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b', 'model': {'self': 'https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/models/base/bb14a731-ed79-407f-b8dc-61f457c79db4'}, 'links': {'files': 'https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b/files'}, 'properties': {'diarizationEnabled': False, 'wordLevelTimestampsEnabled': False, 'channels': [0, 1], 'punctuationMode': 'Automatic', 'profanityFilterMode': 'Masked'}, 'lastActionDateTime': '2022-06-16T06:31:16Z', 'status': 'NotStarted', 'createdDateTime': '2022-06-16T06:31:16Z', 'locale': 'en-US', 'displayName': 'audio.wav'}\n"
     ]
    }
   ],
   "source": [
    "for blob in blob_list:\n",
    "    print(\"\\t\" + blob.name)\n",
    "    RECORDINGS_BLOB_URI = STORAGE_PATH + blob.name + SAS\n",
    "    URL = RECORDINGS_BLOB_URI\n",
    "    blobname = blob.name\n",
    "    r = requests.post(BaseURL, headers=headers,data=bulkTranscription(URL,blobname))\n",
    "    print(r.text)\n",
    "    js = json.loads(r.text)\n",
    "    print(js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all transcriptions in either of the following states (Not Started, Running, Succeeded, Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAllTranscriptions() :\n",
    "    import datetime\n",
    "    df = pd.DataFrame(columns=[\"id\",\"name\", \"status\",\"createdDateTime\",\"lastActionDateTime\",\"CallDuration\"])\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n",
    "    r = requests.get(BaseURL, headers=headers)\n",
    "    js = json.loads(r.text)\n",
    "    #print(js)\n",
    "    for TR in js['values']:\n",
    "        if TR[\"status\"] not in (\"Succeeded\")  :\n",
    "            Dur=\"-\"\n",
    "        else :\n",
    "            Dur = TR[\"properties\"][\"duration\"]\n",
    "        df = df.append({\n",
    "         \"id\":                  TR[\"self\"].split('/')[-1],\n",
    "         \"name\":                TR[\"displayName\"],\n",
    "         \"status\":              TR[\"status\"],\n",
    "         \"createdDateTime\":     datetime.datetime.strptime(TR[\"createdDateTime\"],\"%Y-%m-%dT%H:%M:%SZ\"),            \n",
    "         \"lastActionDateTime\":  datetime.datetime.strptime(TR[\"lastActionDateTime\"],\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "         \"CallDuration\":            Dur      \n",
    "          }, ignore_index=True)\n",
    "        df[\"ProcTime\"] = df[\"lastActionDateTime\"] - df[\"createdDateTime\"]\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>createdDateTime</th>\n",
       "      <th>lastActionDateTime</th>\n",
       "      <th>CallDuration</th>\n",
       "      <th>ProcTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>027d5322-2c97-4677-9040-0c213c23da4b</td>\n",
       "      <td>audio.wav</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>2022-06-16 06:31:16</td>\n",
       "      <td>2022-06-16 06:31:27</td>\n",
       "      <td>PT42S</td>\n",
       "      <td>0 days 00:00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id       name     status  \\\n",
       "0  027d5322-2c97-4677-9040-0c213c23da4b  audio.wav  Succeeded   \n",
       "\n",
       "       createdDateTime   lastActionDateTime CallDuration        ProcTime  \n",
       "0  2022-06-16 06:31:16  2022-06-16 06:31:27        PT42S 0 days 00:00:11  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listAllTranscriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n"
     ]
    }
   ],
   "source": [
    "transcriptions = listAllTranscriptions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through each transcription that finished and is in \"Succeeded\" status and obtain the json output of the transcription. Save the json file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    # Request headers\n",
    "    'Ocp-Apim-Subscription-Key': SUBSCRIPTION_KEY,\n",
    "}\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "    # Request parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [{'self': 'https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b/files/7b50d19d-3e94-4228-82ae-88b828fd81d8', 'name': 'report.json', 'kind': 'TranscriptionReport', 'properties': {'size': 367}, 'createdDateTime': '2022-06-16T06:31:27Z', 'links': {'contentUrl': 'https://spsvcprodweu.blob.core.windows.net/bestor-acc02701-cb45-42dc-9d32-2843911017ca/TranscriptionData/027d5322-2c97-4677-9040-0c213c23da4b_report.json?sv=2021-06-08&st=2022-06-16T06%3A27%3A35Z&se=2022-06-16T18%3A32%3A35Z&sr=b&sp=rl&sig=9S6wIBnu9YuvsfsYfFEgJnF6p2g7YIM7p5s4SLk6IWk%3D'}}, {'self': 'https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.0/transcriptions/027d5322-2c97-4677-9040-0c213c23da4b/files/939f9554-9330-480b-9078-2799d1552eb3', 'name': 'contenturl_0.json', 'kind': 'Transcription', 'properties': {'size': 20435}, 'createdDateTime': '2022-06-16T06:31:27Z', 'links': {'contentUrl': 'https://spsvcprodweu.blob.core.windows.net/bestor-acc02701-cb45-42dc-9d32-2843911017ca/TranscriptionData/027d5322-2c97-4677-9040-0c213c23da4b_0_0.json?sv=2021-06-08&st=2022-06-16T06%3A27%3A35Z&se=2022-06-16T18%3A32%3A35Z&sr=b&sp=rl&sig=2dh7KPg8a4cxfLNNtAFahiGRiQDokMN9PL1HyQpvN%2FU%3D'}}]}\n",
      "https://spsvcprodweu.blob.core.windows.net/bestor-acc02701-cb45-42dc-9d32-2843911017ca/TranscriptionData/027d5322-2c97-4677-9040-0c213c23da4b_0_0.json?sv=2021-06-08&st=2022-06-16T06%3A27%3A35Z&se=2022-06-16T18%3A32%3A35Z&sr=b&sp=rl&sig=2dh7KPg8a4cxfLNNtAFahiGRiQDokMN9PL1HyQpvN%2FU%3D\n",
      "{\n",
      "  \"source\": \"https://fimscogstorage.blob.core.windows.net/speechdata/audio.wav?sv=2021-06-08&ss=b&srt=sco&sp=rwdlacix&se=2022-06-23T09:55:35Z&st=2022-06-16T01:55:35Z&spr=https&sig=Imz4h6XA0BT397ljMkIhSIQAZ920yFdGsg3LAGXnIJM%3D\",\n",
      "  \"timestamp\": \"2022-06-16T06:31:27Z\",\n",
      "  \"durationInTicks\": 420100000,\n",
      "  \"duration\": \"PT42.01S\",\n",
      "  \"combinedRecognizedPhrases\": [\n",
      "    {\n",
      "      \"channel\": 0,\n",
      "      \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "      \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "      \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "      \"display\": \"Once the test is complete, indicated by the status change to succeeded, you'll find a war number for both models included in your test. Click on the test name to view the testing detail page. This detail page lists all the utterances in your data set, indicating the recognition results of the two models, alongside the transcription from the submitted data set. To help inspect the side by side comparison, you can toggle various error types, including insertion, deletion, and substitution by listening to the audio and comparing. Recognition results in each column, which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required.\"\n",
      "    }\n",
      "  ],\n",
      "  \"recognizedPhrases\": [\n",
      "    {\n",
      "      \"recognitionStatus\": \"Success\",\n",
      "      \"channel\": 0,\n",
      "      \"offset\": \"PT0.1S\",\n",
      "      \"duration\": \"PT30.41S\",\n",
      "      \"offsetInTicks\": 1000000.0,\n",
      "      \"durationInTicks\": 304100000.0,\n",
      "      \"nBest\": [\n",
      "        {\n",
      "          \"confidence\": 0.8824719,\n",
      "          \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"display\": \"Once the test is complete, indicated by the status change to succeeded, you'll find a war number for both models included in your test. Click on the test name to view the testing detail page. This detail page lists all the utterances in your data set, indicating the recognition results of the two models, alongside the transcription from the submitted data set. To help inspect the side by side comparison, you can toggle various error types, including insertion, deletion, and substitution by listening to the audio and comparing.\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.882843,\n",
      "          \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\",\n",
      "          \"display\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio and comparing\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.88269746,\n",
      "          \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"display\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.883069,\n",
      "          \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"display\": \"once the test is complete indicated by the status change to succeeded you'll find at war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various error types including insertion deletion and substitution by listening to the audio in comparing\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.8820779,\n",
      "          \"lexical\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various serotypes including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"itn\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various serotypes including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"maskedITN\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various serotypes including insertion deletion and substitution by listening to the audio in comparing\",\n",
      "          \"display\": \"once the test is complete indicated by the status change to succeeded you'll find a war number for both models included in your test click on the test name to view the testing detail page this detail page lists all the utterances in your data set indicating the recognition results of the two models alongside the transcription from the submitted data set to help inspect the side by side comparison you can toggle various serotypes including insertion deletion and substitution by listening to the audio in comparing\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"recognitionStatus\": \"Success\",\n",
      "      \"channel\": 0,\n",
      "      \"offset\": \"PT30.59S\",\n",
      "      \"duration\": \"PT11.25S\",\n",
      "      \"offsetInTicks\": 305900000.0,\n",
      "      \"durationInTicks\": 112500000.0,\n",
      "      \"nBest\": [\n",
      "        {\n",
      "          \"confidence\": 0.86940295,\n",
      "          \"lexical\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"itn\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"maskedITN\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"display\": \"Recognition results in each column, which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required.\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.86080194,\n",
      "          \"lexical\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"itn\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"maskedITN\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\",\n",
      "          \"display\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.86473966,\n",
      "          \"lexical\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"itn\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"maskedITN\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"display\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.85613865,\n",
      "          \"lexical\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"itn\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"maskedITN\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\",\n",
      "          \"display\": \"recognition results in each column which shows the human label transcription and the results for two speech to text models you can decide which model meets your needs and wear additional training and improvements are required\"\n",
      "        },\n",
      "        {\n",
      "          \"confidence\": 0.8629234,\n",
      "          \"lexical\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and were additional training and improvements are required\",\n",
      "          \"itn\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and were additional training and improvements are required\",\n",
      "          \"maskedITN\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and were additional training and improvements are required\",\n",
      "          \"display\": \"recognition results in each column which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and were additional training and improvements are required\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for index, row in transcriptions.iterrows():\n",
    "    if row[\"status\"] in (\"Succeeded\"):\n",
    "        conn = http.client.HTTPSConnection(region + '.api.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/speechtotext/v3.0/transcriptions/\" + row[\"id\"] + \"/files?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        print(json.loads(data))\n",
    "        jsonobj = json.loads(data)\n",
    "        for val in jsonobj['values']:\n",
    "            if val['kind'] == 'Transcription':\n",
    "                contentUrl = val['links']['contentUrl']\n",
    "        print(contentUrl)\n",
    "        r = requests.get(contentUrl, headers=headers)\n",
    "        print(r.text)\n",
    "        json_text = json.loads(r.text)\n",
    "        with open(row['name']+\"_\"+row['id']+\".json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_text, f, ensure_ascii=False, indent=4)\n",
    "    elif row[\"status\"] in (\"Failed\"):\n",
    "        conn = http.client.HTTPSConnection(region + '.api.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/speechtotext/v3.0/transcriptions/\" + row[\"id\"] + \"/files?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        print(json.loads(data))\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate the transcriptions log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteAllTranscriptions() :\n",
    "    trs=listAllTranscriptions()\n",
    "    for x in trs[\"id\"] :\n",
    "        print(x)\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n",
    "        r = requests.delete(BaseURL+x, headers=headers)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n",
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n",
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n",
      "C:\\Users\\faismali\\AppData\\Local\\Temp\\ipykernel_21884\\2131517670.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d468c058-7127-4760-996c-bc1440c5e335\n",
      "<Response [204]>\n",
      "7a43cb3a-e999-4f35-bbc6-6cb906ff409a\n",
      "<Response [204]>\n",
      "7cd04b8e-ba36-4344-996f-29c096457402\n",
      "<Response [204]>\n",
      "d055aad7-54d8-470a-a9e5-655069e3f475\n",
      "<Response [204]>\n"
     ]
    }
   ],
   "source": [
    "deleteAllTranscriptions() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain sentiment scores using Text Analytics for each of the utterances from the transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n",
    "r = requests.get(json.loads(data)['values'][0]['links']['contentUrl'], headers=headers)\n",
    "json_text = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spsvcprodweu.blob.core.windows.net/bestor-acc02701-cb45-42dc-9d32-2843911017ca/TranscriptionData/027d5322-2c97-4677-9040-0c213c23da4b_0_0.json?sv=2021-06-08&st=2022-06-16T06%3A27%3A35Z&se=2022-06-16T18%3A32%3A35Z&sr=b&sp=rl&sig=2dh7KPg8a4cxfLNNtAFahiGRiQDokMN9PL1HyQpvN%2FU%3D\n",
      "https://spsvcprodweu.blob.core.windows.net/bestor-acc02701-cb45-42dc-9d32-2843911017ca/TranscriptionData/027d5322-2c97-4677-9040-0c213c23da4b_0_0.json?sv=2021-06-08&st=2022-06-16T06%3A27%3A35Z&se=2022-06-16T18%3A32%3A35Z&sr=b&sp=rl&sig=2dh7KPg8a4cxfLNNtAFahiGRiQDokMN9PL1HyQpvN%2FU%3D\n"
     ]
    }
   ],
   "source": [
    "for val in jsonobj['values']:\n",
    "    if val['kind'] == 'Transcription':\n",
    "        contentUrl = val['links']['contentUrl']\n",
    "    print(contentUrl)\n",
    "    r = requests.get(contentUrl, headers=headers)\n",
    "    json_text = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once the test is complete, indicated by the status change to succeeded, you'll find a war number for both models included in your test. Click on the test name to view the testing detail page. This detail page lists all the utterances in your data set, indicating the recognition results of the two models, alongside the transcription from the submitted data set. To help inspect the side by side comparison, you can toggle various error types, including insertion, deletion, and substitution by listening to the audio and comparing. Recognition results in each column, which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_text['combinedRecognizedPhrases'][0]['display']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_SUBSCRIPTION_KEY = \"f5356fd659be4adab0b5fa4bb0f66e1a\"\n",
    "## Text to Speech region\n",
    "region = \"westeurope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': TEXT_SUBSCRIPTION_KEY,\n",
    "}\n",
    "\n",
    "text_params = urllib.parse.urlencode({\n",
    "    # Request parameters\n",
    "})\n",
    "\n",
    "docs = {\"documents\": [\n",
    "           {\n",
    "               \"language\": \"en\",\n",
    "               \"id\" : \"1\",\n",
    "               \"text\": json_text['combinedRecognizedPhrases'][0]['display']\n",
    "               \n",
    "           }\n",
    "]}\n",
    "\n",
    "\n",
    "try:\n",
    "    conn = http.client.HTTPSConnection(region + '.api.cognitive.microsoft.com')\n",
    "    conn.request(\"POST\", \"/text/analytics/v3.1/sentiment?%s\" % text_params, json.dumps(docs), text_headers)\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    \n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'id': '1',\n",
       "   'sentiment': 'negative',\n",
       "   'confidenceScores': {'positive': 0.01, 'neutral': 0.09, 'negative': 0.9},\n",
       "   'sentences': [{'sentiment': 'neutral',\n",
       "     'confidenceScores': {'positive': 0.07, 'neutral': 0.77, 'negative': 0.16},\n",
       "     'offset': 0,\n",
       "     'length': 136,\n",
       "     'text': \"Once the test is complete, indicated by the status change to succeeded, you'll find a war number for both models included in your test. \"},\n",
       "    {'sentiment': 'neutral',\n",
       "     'confidenceScores': {'positive': 0.0, 'neutral': 0.99, 'negative': 0.01},\n",
       "     'offset': 136,\n",
       "     'length': 56,\n",
       "     'text': 'Click on the test name to view the testing detail page. '},\n",
       "    {'sentiment': 'neutral',\n",
       "     'confidenceScores': {'positive': 0.01, 'neutral': 0.98, 'negative': 0.01},\n",
       "     'offset': 192,\n",
       "     'length': 171,\n",
       "     'text': 'This detail page lists all the utterances in your data set, indicating the recognition results of the two models, alongside the transcription from the submitted data set. '},\n",
       "    {'sentiment': 'negative',\n",
       "     'confidenceScores': {'positive': 0.01, 'neutral': 0.09, 'negative': 0.9},\n",
       "     'offset': 363,\n",
       "     'length': 170,\n",
       "     'text': 'To help inspect the side by side comparison, you can toggle various error types, including insertion, deletion, and substitution by listening to the audio and comparing. '},\n",
       "    {'sentiment': 'neutral',\n",
       "     'confidenceScores': {'positive': 0.02, 'neutral': 0.97, 'negative': 0.01},\n",
       "     'offset': 533,\n",
       "     'length': 230,\n",
       "     'text': 'Recognition results in each column, which shows the human labeled transcription and the results for two speech to text models you can decide which model meets your needs and where additional training and improvements are required.'}],\n",
       "   'warnings': []}],\n",
       " 'errors': [],\n",
       " 'modelVersion': '2021-10-01'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
